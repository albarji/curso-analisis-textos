{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Ejercicio: an\u00e1lisis morfol\u00f3gico y aplicaci\u00f3n a opiniones sobre pel\u00edculas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"img/drama.png\" style=\"width:400px;height:400px;\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En este ejercicio vamos a utilizar cr\u00edticas escritas en [IMDB](http://www.imdb.com/) para tratar de extraer autom\u00e1ticamente la opini\u00f3n expresada, positiva o negativa, de un texto. Para ello utilizamos algunas t\u00e9cnicas t\u00e9cnicas de an\u00e1lisis morfol\u00f3gico del texto.\n", "\n", "El objetivo del ejercicio es construir un sistema que dado el texto en ingl\u00e9s de una cr\u00edtica sea capaz de estimar si esa cr\u00edtica expresa una opini\u00f3n positiva o negativa. Empezaremos construyendo un clasificador de opini\u00f3n sencillo, para ir introduciendo caracter\u00edsticas cada vez m\u00e1s complicadas e ir mejorando nuestros resultados."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Instrucciones"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A lo largo de este cuaderno encontrar\u00e1s celdas vac\u00edas que tendr\u00e1s que rellenar con tu propio c\u00f3digo. Sigue las instrucciones del cuaderno y presta especial atenci\u00f3n a los siguientes iconos:\n", "\n", "<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Deber\u00e1s responder a la pregunta indicada con el c\u00f3digo o contestaci\u00f3n que escribas en la celda inferior.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Esto es una pista u observaci\u00f3n que te puede ayudar a resolver la pr\u00e1ctica.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Este es un ejercicio avanzado y voluntario que puedes realizar si quieres profundar m\u00e1s sobre el tema. Te animamos a intentarlo para aprender m\u00e1s \u00a1\u00c1nimo!</td></tr>\n", "</table>\n", "\n", "Para evitar problemas de compatibilidad y de paquetes no instalados, se recomienda ejecutar este notebook bajo uno de los [entornos recomendados de Text Mining](https://github.com/albarji/teaching-environments/tree/master/textmining).\n", "\n", "Adicionalmente si necesitas consultar la ayuda de cualquier funci\u00f3n python puedes colocar el cursor de escritura sobre el nombre de la misma y pulsar May\u00fasculas+Shift para que aparezca un recuadro con sus detalles. Ten en cuenta que esto \u00fanicamente funciona en las celdas de c\u00f3digo.\n", "\n", "\u00a1Adelante!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminares"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En primer lugar vamos a fijar la semilla aleatoria para que los resultados sean reproducibles entre diferentes ejecuciones del notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "np.random.seed(12345)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Carga y preparaci\u00f3n de datos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Los datos que usaremos en esta pr\u00e1ctica son un conjunto preparado de los datos empleados en el art\u00edculo\n", "\n", "    Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).\n", "    \n", "y consisten en cr\u00edticas de pel\u00edculas escritas en la web en ingl\u00e9s IMDB. Se han tomado aquellas cr\u00edticas con una puntuaci\u00f3n mayor a 7 como **opiniones positivas**, mientras que aquellas con puntuaci\u00f3n menor a 4 se han tomado como **opiniones negativas**.\n", "\n", "Los datos est\u00e1n todos contenidos en el fichero *data/data.csv*, en formato CSV separado por tabuladores. El fichero contiene \u00fanicamente dos columnas, la primera de ellas indicando el tipo de opini\u00f3n (1 = opini\u00f3n positiva, 0 = opini\u00f3n negativa) y la segunda de ellas el texto de la cr\u00edtica."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Carga en un Dataframe de Pandas los datos del fichero <i>data/data.csv</i>. Analiza los primeros registros del Dataframe. \u00bfParecen coherentes los valores de opini\u00f3n con el texto?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    El fichero cargado arriba es una versi\u00f3n reducida del conjunto completo de datos. Si quieres optar por usar todos los datos para esta pr\u00e1ctica puedes cargar el fichero <i>data/datafull.csv.gz</i>. Ten en cuenta que los tiempos de c\u00e1lculo ser\u00e1n mucho mayores, aunque a cambio podr\u00e1s conseguir mejores resultados de clasificaci\u00f3n.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora vamos a preparar dos listas de \u00edndices, que nos indiquen qu\u00e9 parte de los datos vamos a usar para entrenamiento y qu\u00e9 parte para test."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Genera dos listas, una conteniendo los \u00edndices de la primera mitad de las filas del DataFrame de datos (\u00edndices de train), y otra conteniendo los \u00edndices de la otra mitad (\u00edndices de test).\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Modelo inicial"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para poder valorar si las t\u00e9cnicas avanzadas que vamos a emplear aportan algo de utilidad a este problema, vamos a empezar con una soluci\u00f3n muy sencilla basada en bag of words, estimando la precisi\u00f3n de clasificaci\u00f3n que podemos obtener con ella y usando este valor como referencia."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Utilizando lo que has aprendido en la pr\u00e1ctica anterior, construye un sistema de clasificaci\u00f3n basado en unigramas de palabras que aprenda de los datos de entrenamiento, y calcula el error de estimaci\u00f3n en test del mismo. Como modelo de clasificaci\u00f3n utiliza una SVM lineal, con sus par\u00e1metros por defecto. No realices ning\u00fan proceso de b\u00fasqueda para optimizar los par\u00e1metros del modelo (tipo GridSearchCV).\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    El nivel de precisi\u00f3n que has obtenido, \u00bfcrees que ser\u00eda adecuado para una aplicaci\u00f3n real? \u00bfPiensas que puede mejorarse?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## An\u00e1lisis morfosint\u00e1tico con spaCy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En entornos donde existe mucho texto expresado de forma natural lo habitual es que una palabra aparezca con diversas conjugaciones y formas, sin que el significado final del texto cambie demasiado (salvo matices que discutiremos m\u00e1s adelante). En estos casos un paso de preprocesamiento habitual es convertir las palabras a lemas, o eliminar categor\u00edas morfol\u00f3gicas que aportan poca informaci\u00f3n. Para esto es imprescindible realizar un **an\u00e1lisis morfosint\u00e1ctico** del texto, lo cual podemos hacer f\u00e1cilmente para diversos idiomas utilizando la librer\u00eda **spaCy**."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import spacy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["spaCy utiliza modelos morfosint\u00e1cticos espec\u00edficos para cada idioma. Por defecto la librer\u00eda no incluye ning\u00fan modelo, pero podemos instalarlo de manera sencilla con comandos a python. La siguiente l\u00ednea ejecuta un comando de sistema para instalar el modelo de spaCy para el idioma ingl\u00e9s."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!python -m spacy download en"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Si el comando anterior produce un error relacionado con la falta de permisos, deber\u00e1s ejecutarlo desde una terminal de Anaconda lanzada con permisos de administrador.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez obtenido el modelo, podemos cargarlo en memoria con"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nlp = spacy.load('en')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["y analizar una frase de ejemplo de la siguiente manera"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frase = \"The black cat sat peacefully on the mat.\"\n", "doc = nlp(frase)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**doc** es ahora una versi\u00f3n de la frase que contiene toda la informaci\u00f3n morfol\u00f3gica y sint\u00e1ctica extra\u00edda por el analizador. Podemos iterar sobre cada uno de los tokens de la frase de la siguiente forma"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for token in doc:\n", "    print(\"Token:\", token)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Igualmente podemos acceder a cada uno de los tokens por su posici\u00f3n en la frase"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(doc[2])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pero lo m\u00e1s interesante son los diferentes campos con informaci\u00f3n extra que contiene cada token. Campos como\n", "* *texto*: texto original\n", "* *lemma_*: lema\n", "* *pos_*: Part of Speech (categor\u00eda morfol\u00f3gica) simple\n", "* *tag_*: categor\u00eda morfol\u00f3gica detallada\n", "* *shape_*: patr\u00f3n de may\u00fasculas/min\u00fasculas\n", "* *is_alpha*: si el token se componente de caracteres alfab\u00e9ticos\n", "* *is_stop*: si el token ha sido detectado como una stopword\n", "* *head*: token padre en el \u00e1rbol de dependencia\n", "* *dep_*: relaci\u00f3n sint\u00e1ctica con el token padre\n", "* etc..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Por ejemplo, vamos a imprimir toda esta informaci\u00f3n para el primer token de la frase"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["token = doc[0]\n", "print(\"Texto:\", token.text)\n", "print(\"Lema:\", token.lemma_)\n", "print(\"POS:\", token.pos_)\n", "print(\"Tag:\", token.tag_)\n", "print(\"Forma:\", token.shape_)\n", "print(\"Es alpha:\", token.is_alpha)\n", "print(\"Es stopword:\", token.is_stop)\n", "print(\"Token padre:\", token.head)\n", "print(\"Relaci\u00f3n sint\u00e1ctica:\", token.dep_)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos hacer esto con toda la frase y mostrarlo como una tabla (DataFrame) para mayor claridad"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pd.DataFrame(\n", "    columns=[\"token\", \"lema\", \"POS\", \"tag\", \"shap\", \"isalpha\", \"isstop\", \"padre\", \"dep\"],\n", "    data=[[token.text, token.lemma_, token.pos_, token.tag_,\n", "          token.shape_, token.is_alpha, token.is_stop, token.head, token.dep_]\n", "          for token in doc]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tambi\u00e9n podemos visualizar el \u00e1rbol sint\u00e1tico de dependencias usando la utilidad **displaCy**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["from spacy import displacy\n", "\n", "displacy.render(doc, style='dep', jupyter=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Como hemos visto, el an\u00e1lisis morfosint\u00e1ctico de spaCy nos proporciona mucha informaci\u00f3n, pero tambi\u00e9n puede ser costoso de realizar cuando tenemos gran cantidad de textos. Si no necesitamos de todos los componentes del an\u00e1lisis, podemos acelerar el tiempo de c\u00e1lculo desactivando algunos elementos del proceso. Por ejemplo, cargando de nuevo el modelo de la siguiente forma"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nlpfast = spacy.load('en', disable=['ner', 'parser'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Con esto tenemos un analizador morfosint\u00e1ctico que no realiza detecci\u00f3n de entidades (`ner`) ni an\u00e1lisis del \u00e1rbol sint\u00e1ctico de dependencias (`parser`), pero que a cambio ejecuta a mayor velocidad, como podemos comprobar en las siguientes dos celdas."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "for _ in range(10):\n", "    nlp(\"The black cat sat peacefully on the mat.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%time\n", "for _ in range(10):\n", "    nlpfast(\"The black cat sat peacefully on the mat.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visto el funcionamiento de spaCy, vamos a pasar a ejecutar el an\u00e1lisis morfosint\u00e1ctico para cada texto de nuestros datos."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Crea una nueva columna en el DataFrame de datos que contenga una versi\u00f3n analizada con spaCy del texto correspondiente. Es suficiente con que apliques el objeto <b>nlp</b> a cada texto y guardes el resultado.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Filtrado por morfolog\u00eda"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos a sacar partido a la informaci\u00f3n morfol\u00f3gica que nos proporciona spaCy para mejorar el modelo predictivo. Para ello realizaremos dos operaciones:\n", "\n", "* Filtrar los textos para quedarnos solo con aquellas palabras de las categor\u00edas morfol\u00f3gicas con m\u00e1s carga de emoci\u00f3n.\n", "* Filtrar los textos para no incluir palabras stopwords.\n", "* Sustituir cada token por su lema, para as\u00ed reducir el tama\u00f1o del vocabulario y simplificar el problema."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Crea una nueva columna en el DataFrame de datos que contenga una versi\u00f3n modificado del texto con \u00fanicamente los lemas de aquellos tokens cuyas etiquetas POS sean de clase <b>nombre</b>, <b>verbo</b>, <b>adjetivo</b> o <b>adverbio</b>.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Repite los pasos que realizaste en el caso del modelo inicial (al inicio de esta pr\u00e1ctica) para construir un nuevo modelo, esta vez basado en los textos que has preparados en lugar de los textos originales. Mide el nivel de score sobre el conjunto de test, \u00bfhas conseguido alguna mejora en precisi\u00f3n? \u00bfY en tiempos de entrenamiento?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 1}