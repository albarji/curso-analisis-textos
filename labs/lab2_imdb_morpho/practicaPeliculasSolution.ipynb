{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: análisis morfológico y aplicación a opiniones sobre películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/drama.png\" style=\"width:400px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a utilizar críticas escritas en [IMDB](http://www.imdb.com/) para tratar de extraer automáticamente la opinión expresada, positiva o negativa, de un texto. Para ello utilizamos algunas técnicas técnicas de análisis morfológico del texto.\n",
    "\n",
    "El objetivo del ejercicio es construir un sistema que dado el texto en inglés de una crítica sea capaz de estimar si esa crítica expresa una opinión positiva o negativa. Empezaremos construyendo un clasificador de opinión sencillo, para ir introduciendo características cada vez más complicadas e ir mejorando nuestros resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de este cuaderno encontrarás celdas vacías que tendrás que rellenar con tu propio código. Sigue las instrucciones del cuaderno y presta especial atención a los siguientes iconos:\n",
    "\n",
    "<table>\n",
    "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Deberás responder a la pregunta indicada con el código o contestación que escribas en la celda inferior.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Esto es una pista u observación que te puede ayudar a resolver la práctica.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Este es un ejercicio avanzado y voluntario que puedes realizar si quieres profundar más sobre el tema. Te animamos a intentarlo para aprender más ¡Ánimo!</td></tr>\n",
    "</table>\n",
    "\n",
    "Para evitar problemas de compatibilidad y de paquetes no instalados, se recomienda ejecutar este notebook bajo uno de los [entornos recomendados de Text Mining](https://github.com/albarji/teaching-environments/tree/master/textmining).\n",
    "\n",
    "Adicionalmente si necesitas consultar la ayuda de cualquier función python puedes colocar el cursor de escritura sobre el nombre de la misma y pulsar Mayúsculas+Shift para que aparezca un recuadro con sus detalles. Ten en cuenta que esto únicamente funciona en las celdas de código.\n",
    "\n",
    "¡Adelante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a fijar la semilla aleatoria para que los resultados sean reproducibles entre diferentes ejecuciones del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que usaremos en esta práctica son un conjunto preparado de los datos empleados en el artículo\n",
    "\n",
    "    Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).\n",
    "    \n",
    "y consisten en críticas de películas escritas en la web en inglés IMDB. Se han tomado aquellas críticas con una puntuación mayor a 7 como **opiniones positivas**, mientras que aquellas con puntuación menor a 4 se han tomado como **opiniones negativas**.\n",
    "\n",
    "Los datos están todos contenidos en el fichero *data/data.csv*, en formato CSV separado por tabuladores. El fichero contiene únicamente dos columnas, la primera de ellas indicando el tipo de opinión (1 = opinión positiva, 0 = opinión negativa) y la segunda de ellas el texto de la crítica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "      Carga en un Dataframe de Pandas los datos del fichero <i>data/data.csv</i>. Analiza los primeros registros del Dataframe. ¿Parecen coherentes los valores de opinión con el texto?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  I simply cant understand why all these relics ...\n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...\n",
       "2          1  It could have been a better film. It does drag...\n",
       "3          1  It is very hard to rate this film. As entertai...\n",
       "4          1  I've read some terrible things about this film..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/data.csv\", sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    El fichero cargado arriba es una versión reducida del conjunto completo de datos. Si quieres optar por usar todos los datos para esta práctica puedes cargar el fichero <i>data/datafull.csv.gz</i>. Ten en cuenta que los tiempos de cálculo serán mucho mayores, aunque a cambio podrás conseguir mejores resultados de clasificación.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "#data = pd.read_csv(\"./data/datafull.csv\", sep='\\t')\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a preparar dos listas de índices, que nos indiquen qué parte de los datos vamos a usar para entrenamiento y qué parte para test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Genera dos listas, una conteniendo los índices de la primera mitad de las filas del DataFrame de datos (índices de train), y otra conteniendo los índices de la otra mitad (índices de test).\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import math\n",
    "nrows = data.shape[0]\n",
    "splitpoint = math.floor(nrows * 0.50)\n",
    "trainidx = list(range(splitpoint))\n",
    "testidx = list(range(splitpoint, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder valorar si las técnicas avanzadas que vamos a emplear aportan algo de utilidad a este problema, vamos a empezar con una solución muy sencilla basada en bag of words, estimando la precisión de clasificación que podemos obtener con ella y usando este valor como referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Utilizando lo que has aprendido en la práctica anterior, construye un sistema de clasificación basado en unigramas de palabras que aprenda de los datos de entrenamiento, y calcula el error de estimación en test del mismo. Como modelo de clasificación utiliza una SVM lineal, con sus parámetros por defecto. No realices ningún proceso de búsqueda para optimizar los parámetros del modelo (tipo GridSearchCV).\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/miniconda3/envs/textmining-labs/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LinearSVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'vectorizer__analyzer' : ['word'],\n",
    "    'vectorizer__ngram_range' : [(1, 1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, params, n_jobs = 7)\n",
    "\n",
    "model.fit(data[\"text\"][trainidx].values, data[\"sentiment\"][trainidx])\n",
    "model.score(data[\"text\"][testidx].values, data[\"sentiment\"][testidx])\n",
    "\n",
    "# 0.80 con datos pequeños\n",
    "# 0.88544 con datos grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    El nivel de precisión que has obtenido, ¿crees que sería adecuado para una aplicación real? ¿Piensas que puede mejorarse?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis morfosintático con spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En entornos donde existe mucho texto expresado de forma natural lo habitual es que una palabra aparezca con diversas conjugaciones y formas, sin que el significado final del texto cambie demasiado (salvo matices que discutiremos más adelante). En estos casos un paso de preprocesamiento habitual es convertir las palabras a lemas, o eliminar categorías morfológicas que aportan poca información. Para esto es imprescindible realizar un **análisis morfosintáctico** del texto, lo cual podemos hacer fácilmente para diversos idiomas utilizando la librería **spaCy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy utiliza modelos morfosintácticos específicos para cada idioma. Por defecto la librería no incluye ningún modelo, pero podemos instalarlo de manera sencilla con comandos a python. La siguiente línea ejecuta un comando de sistema para instalar el modelo de spaCy para el idioma inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 68.9MB/s ta 0:00:01    46% |███████████████                 | 17.5MB 28.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/alvaro/miniconda3/envs/textmining-labs/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/alvaro/miniconda3/envs/textmining-labs/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Si el comando anterior produce un error relacionado con la falta de permisos, deberás ejecutarlo desde una terminal de Anaconda lanzada con permisos de administrador.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez obtenido el modelo, podemos cargarlo en memoria con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y analizar una frase de ejemplo de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"The black cat sat peacefully on the mat.\"\n",
    "doc = nlp(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**doc** es ahora una versión de la frase que contiene toda la información morfológica y sintáctica extraída por el analizador. Podemos iterar sobre cada uno de los tokens de la frase de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The\n",
      "Token: black\n",
      "Token: cat\n",
      "Token: sat\n",
      "Token: peacefully\n",
      "Token: on\n",
      "Token: the\n",
      "Token: mat\n",
      "Token: .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"Token:\", token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igualmente podemos acceder a cada uno de los tokens por su posición en la frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(doc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero lo más interesante son los diferentes campos con información extra que contiene cada token. Campos como\n",
    "* *texto*: texto original\n",
    "* *lemma_*: lema\n",
    "* *pos_*: Part of Speech (categoría morfológica) simple\n",
    "* *tag_*: categoría morfológica detallada\n",
    "* *shape_*: patrón de mayúsculas/minúsculas\n",
    "* *is_alpha*: si el token se componente de caracteres alfabéticos\n",
    "* *is_stop*: si el token ha sido detectado como una stopword\n",
    "* *head*: token padre en el árbol de dependencia\n",
    "* *dep_*: relación sintáctica con el token padre\n",
    "* etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, vamos a imprimir toda esta información para el primer token de la frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: The\n",
      "Lema: the\n",
      "POS: DET\n",
      "Tag: DT\n",
      "Forma: Xxx\n",
      "Es alpha: True\n",
      "Es stopword: False\n",
      "Token padre: cat\n",
      "Relación sintáctica: det\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(\"Texto:\", token.text)\n",
    "print(\"Lema:\", token.lemma_)\n",
    "print(\"POS:\", token.pos_)\n",
    "print(\"Tag:\", token.tag_)\n",
    "print(\"Forma:\", token.shape_)\n",
    "print(\"Es alpha:\", token.is_alpha)\n",
    "print(\"Es stopword:\", token.is_stop)\n",
    "print(\"Token padre:\", token.head)\n",
    "print(\"Relación sintáctica:\", token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer esto con toda la frase y mostrarlo como una tabla (DataFrame) para mayor claridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lema</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "      <th>shap</th>\n",
       "      <th>isalpha</th>\n",
       "      <th>isstop</th>\n",
       "      <th>padre</th>\n",
       "      <th>dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>black</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cat</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sat</td>\n",
       "      <td>sit</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peacefully</td>\n",
       "      <td>peacefully</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>sat</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>mat</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mat</td>\n",
       "      <td>mat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>on</td>\n",
       "      <td>pobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sat</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token        lema    POS  tag  shap  isalpha  isstop padre     dep\n",
       "0         The         the    DET   DT   Xxx     True   False   cat     det\n",
       "1       black       black    ADJ   JJ  xxxx     True   False   cat    amod\n",
       "2         cat         cat   NOUN   NN   xxx     True   False   sat   nsubj\n",
       "3         sat         sit   VERB  VBD   xxx     True   False   sat    ROOT\n",
       "4  peacefully  peacefully    ADV   RB  xxxx     True   False   sat  advmod\n",
       "5          on          on    ADP   IN    xx     True    True   sat    prep\n",
       "6         the         the    DET   DT   xxx     True    True   mat     det\n",
       "7         mat         mat   NOUN   NN   xxx     True   False    on    pobj\n",
       "8           .           .  PUNCT    .     .    False   False   sat   punct"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    columns=[\"token\", \"lema\", \"POS\", \"tag\", \"shap\", \"isalpha\", \"isstop\", \"padre\", \"dep\"],\n",
    "    data=[[token.text, token.lemma_, token.pos_, token.tag_,\n",
    "          token.shape_, token.is_alpha, token.is_stop, token.head, token.dep_]\n",
    "          for token in doc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos visualizar el árbol sintático de dependencias usando la utilidad **displaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"733-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">black</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">peacefully</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">mat.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-733-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-733-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto, el análisis morfosintáctico de spaCy nos proporciona mucha información, pero también puede ser costoso de realizar cuando tenemos gran cantidad de textos. Si no necesitamos de todos los componentes del análisis, podemos acelerar el tiempo de cálculo desactivando algunos elementos del proceso. Por ejemplo, cargando de nuevo el modelo de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpfast = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto tenemos un analizador morfosintáctico que no realiza detección de entidades (`ner`) ni análisis del árbol sintáctico de dependencias (`parser`), pero que a cambio ejecuta a mayor velocidad, como podemos comprobar en las siguientes dos celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 588 ms, sys: 0 ns, total: 588 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    nlp(\"The black cat sat peacefully on the mat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 0 ns, total: 140 ms\n",
      "Wall time: 34.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    nlpfast(\"The black cat sat peacefully on the mat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto el funcionamiento de spaCy, vamos a pasar a ejecutar el análisis morfosintáctico para cada texto de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Crea una nueva columna en el DataFrame de datos que contenga una versión analizada con spaCy del texto correspondiente. Es suficiente con que apliques el objeto <b>nlp</b> a cada texto y guardes el resultado.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>analyzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "      <td>(I, simply, ca, nt, understand, why, all, thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "      <td>(Director, Raoul, Walsh, was, like, the, Micha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "      <td>(It, could, have, been, a, better, film, ., It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "      <td>(It, is, very, hard, to, rate, this, film, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "      <td>(I, 've, read, some, terrible, things, about, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  I simply cant understand why all these relics ...   \n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...   \n",
       "2          1  It could have been a better film. It does drag...   \n",
       "3          1  It is very hard to rate this film. As entertai...   \n",
       "4          1  I've read some terrible things about this film...   \n",
       "\n",
       "                                            analyzed  \n",
       "0  (I, simply, ca, nt, understand, why, all, thes...  \n",
       "1  (Director, Raoul, Walsh, was, like, the, Micha...  \n",
       "2  (It, could, have, been, a, better, film, ., It...  \n",
       "3  (It, is, very, hard, to, rate, this, film, ., ...  \n",
       "4  (I, 've, read, some, terrible, things, about, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "def addanalyzed(df):\n",
    "    analyzed = [nlp(text) for text in df[\"text\"]]\n",
    "    df[\"analyzed\"] = pd.Series(analyzed, index = df.index)\n",
    "    \n",
    "addanalyzed(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado por morfología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a sacar partido a la información morfológica que nos proporciona spaCy para mejorar el modelo predictivo. Para ello realizaremos dos operaciones:\n",
    "\n",
    "* Filtrar los textos para quedarnos solo con aquellas palabras de las categorías morfológicas con más carga de emoción.\n",
    "* Filtrar los textos para no incluir palabras stopwords.\n",
    "* Sustituir cada token por su lema, para así reducir el tamaño del vocabulario y simplificar el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Crea una nueva columna en el DataFrame de datos que contenga una versión modificado del texto con únicamente los lemas de aquellos tokens cuyas etiquetas POS sean de clase <b>nombre</b>, <b>verbo</b>, <b>adjetivo</b> o <b>adverbio</b>.\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>analyzed</th>\n",
       "      <th>posfilter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I simply cant understand why all these relics ...</td>\n",
       "      <td>(I, simply, ca, nt, understand, why, all, thes...</td>\n",
       "      <td>simply not understand relic era refuse let cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Director Raoul Walsh was like the Michael Bay ...</td>\n",
       "      <td>(Director, Raoul, Walsh, was, like, the, Micha...</td>\n",
       "      <td>year mean positive way be definitely be not ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>It could have been a better film. It does drag...</td>\n",
       "      <td>(It, could, have, been, a, better, film, ., It...</td>\n",
       "      <td>good film drag point central story shift compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>It is very hard to rate this film. As entertai...</td>\n",
       "      <td>(It, is, very, hard, to, rate, this, film, ., ...</td>\n",
       "      <td>hard rate film entertainment value 21st centur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I've read some terrible things about this film...</td>\n",
       "      <td>(I, 've, read, some, terrible, things, about, ...</td>\n",
       "      <td>have read terrible thing film prepare bad conf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          0  I simply cant understand why all these relics ...   \n",
       "1          1  Director Raoul Walsh was like the Michael Bay ...   \n",
       "2          1  It could have been a better film. It does drag...   \n",
       "3          1  It is very hard to rate this film. As entertai...   \n",
       "4          1  I've read some terrible things about this film...   \n",
       "\n",
       "                                            analyzed  \\\n",
       "0  (I, simply, ca, nt, understand, why, all, thes...   \n",
       "1  (Director, Raoul, Walsh, was, like, the, Micha...   \n",
       "2  (It, could, have, been, a, better, film, ., It...   \n",
       "3  (It, is, very, hard, to, rate, this, film, ., ...   \n",
       "4  (I, 've, read, some, terrible, things, about, ...   \n",
       "\n",
       "                                           posfilter  \n",
       "0  simply not understand relic era refuse let cle...  \n",
       "1  year mean positive way be definitely be not ha...  \n",
       "2  good film drag point central story shift compl...  \n",
       "3  hard rate film entertainment value 21st centur...  \n",
       "4  have read terrible thing film prepare bad conf...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "def addposfilter(df):\n",
    "    posfilter = [\" \".join([token.lemma_ for token in text \n",
    "                           if token.pos_ in {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"} and not token.is_stop]) \n",
    "                 for text in df[\"analyzed\"]]\n",
    "    df[\"posfilter\"] = pd.Series(posfilter, index = df.index)\n",
    "    \n",
    "addposfilter(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr>\n",
    "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "    Repite los pasos que realizaste en el caso del modelo inicial (al inicio de esta práctica) para construir un nuevo modelo, esta vez basado en los textos que has preparados en lugar de los textos originales. Mide el nivel de score sobre el conjunto de test, ¿has conseguido alguna mejora en precisión? ¿Y en tiempos de entrenamiento?\n",
    "  </td>\n",
    " </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/miniconda3/envs/textmining-labs/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8056"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LinearSVC())\n",
    "    ]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'vectorizer__analyzer' : ['word'],\n",
    "    'vectorizer__ngram_range' : [(1, 1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, params, n_jobs = 7)\n",
    "model.fit(data[\"posfilter\"][trainidx].values, data[\"sentiment\"][trainidx])\n",
    "model.score(data[\"posfilter\"][testidx].values, data[\"sentiment\"][testidx])\n",
    "\n",
    "# Best small: 0.8088  (lemmas, filter stopwords)\n",
    "# Small: 0.8056 (lemmas, filter stopwords, filter pos NOUN VERB ADJ ADV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
