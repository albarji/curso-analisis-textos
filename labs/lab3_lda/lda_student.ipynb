{"cells": [{"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["# Ejercicio: an\u00e1lisis sem\u00e1ntico de grupos de conversaci\u00f3n"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["<img src=\"img/news.jpg\">"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["En este ejercicio vamos a realizar el an\u00e1lisis sem\u00e1ntico de unos grupos de conversaci\u00f3n sobre noticias. Para ello emplearemos t\u00e9cnicas como Latent Dirichlet Allocation que nos permitan detectar tem\u00e1ticas de conversaci\u00f3n de forma autom\u00e1tica. Comprobaremos tambi\u00e9n si la detecci\u00f3n de estas tem\u00e1ticas puede sernos de utilidad para un problema de clasificaci\u00f3n supervisada. \u00a1Adelante!"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["## Instrucciones"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["A lo largo de este cuaderno encontrar\u00e1s celdas vac\u00edas que tendr\u00e1s que rellenar con tu propio c\u00f3digo. Sigue las instrucciones del cuaderno y presta especial atenci\u00f3n a los siguientes iconos:\n", "\n", "<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Deber\u00e1s responder a la pregunta indicada con el c\u00f3digo o contestaci\u00f3n que escribas en la celda inferior.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Esto es una pista u observaci\u00f3n que te puede ayudar a resolver la pr\u00e1ctica.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Este es un ejercicio avanzado y voluntario que puedes realizar si quieres profundar m\u00e1s sobre el tema. Te animamos a intentarlo para aprender m\u00e1s \u00a1\u00c1nimo!</td></tr>\n", "</table>\n", "\n", "Para evitar problemas de compatibilidad y de paquetes no instalados, se recomienda ejecutar este notebook bajo uno de los [entornos recomendados de Text Mining](https://github.com/albarji/teaching-environments/tree/master/textmining).\n", "\n", "Adicionalmente si necesitas consultar la ayuda de cualquier funci\u00f3n python puedes colocar el cursor de escritura sobre el nombre de la misma y pulsar May\u00fasculas+Shift para que aparezca un recuadro con sus detalles. Ten en cuenta que esto \u00fanicamente funciona en las celdas de c\u00f3digo.\n", "\n", "\u00a1Adelante!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Carga de datos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En primer lugar vamos a cargar el corpus con el que trabajaremos. Se trata del corpus **newsgroups20**, de referencia en el campo, y que est\u00e1 f\u00e1cilmente disponible a trav\u00e9s de scikit-learn. Con las siguientes instrucciones cargamos en memoria los datos del conjunto de entrenamiento y test del corpus, as\u00ed como realizamos una limpieza b\u00e1sica:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import fetch_20newsgroups\n", "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n", "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Los textos vienen etiquetados seg\u00fan el grupo de conversaci\u00f3n al que pertenencen. Como podemos ver, existen 20 grupos de conversaci\u00f3n, y de ah\u00ed el nombre del corpus:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["set(newsgroups_train.target)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El significado de estos grupos de conversaci\u00f3n numerados del 0 al 19 es el siguiente. Como vemos, aunque varios de los temas se centran en inform\u00e1tica, existen otros grupos variados: automovilismo, deportes, religi\u00f3n, atletismo, ..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["newsgroups_train.target_names"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Contamos adem\u00e1s con bastantes textos en el conjunto de entrenamiento:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["len(newsgroups_train.data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Veamos un ejemplo de un texto de un corpus, y el grupo al que est\u00e1 asociado:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Texto:\\n\\n\", newsgroups_train.data[0])\n", "print(\"\")\n", "print(\"Grupo asociado:\", newsgroups_train.target_names[newsgroups_train.target[0]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## An\u00e1lisis de temas con LDA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora vamos a emplear **Latent Dirichlet Allocation** (LDA) para intentar descubrir los temas de conversaci\u00f3n existentes. LDA es un m\u00e9todo no supervisado, lo que significa que solo requiere de los textos para trabajar, y no necesita de informaci\u00f3n etiquetada sobre la tem\u00e1tica de estos textos. En este corpus concreto ya conocemos de antemano los 20 temas en los que se agrupan los textos, lo cual es un campo de pruebas ideal para ver si LDA es capaz de encontrar a ciegas estos temas, o algunos similares."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Limpieza de datos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para obtener un an\u00e1lisis limpio necesitaremos tokenizar los textos, y eliminar s\u00edmbolos de puntuaci\u00f3n y aquellas palabras que no sean relevantes. Todo esto se puede hacer con los vectorizadores de scikit-learn que ya conocemos. En esta ocasi\u00f3n vamos a emplear TF-IDF, que al dar poco peso a palabras habituales del lenguaje es un buen punto de partida para detectar temas de conversaci\u00f3n diferenciados. Comenzamos construyendo el vectorizador"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "vectorizer = TfidfVectorizer(stop_words='english', min_df=10)\n", "vectorizer.fit(newsgroups_train.data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora podemos aplicarlo sobre los datos de entrenamiento:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vects = vectorizer.transform(newsgroups_train.data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Con esto hemos obtenido una representaci\u00f3n vectorizal de los textos, que como es habitual est\u00e1 almacenada en una matriz sparse para ahorrar espacio en memoria:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vects"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Construcci\u00f3n del modelo LDA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La propia librer\u00eda de aprendizaje autom\u00e1tico scikit-learn incluye m\u00e9todos muy pr\u00e1cticos para aplicar LDA. En particular, LDA est\u00e1 implementado en la clase **LatentDirichletAllocation**. Vamos a crear un transformador de esta clase, indic\u00e1ndole que queremos que trate de encontrar 20 temas en los datos."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import LatentDirichletAllocation\n", "\n", "lda = LatentDirichletAllocation(n_components=20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Los objetos del tipo LatentDirichletAllocation siguen la misma interfaz que otros transformadores de scikit-learn como puede ser TfidfVectorizer. Esto es, disponen de un m\u00e9todo **fit** para entrenarlos, y una vez entrenados pueden ser empleados para transformar otros conjuntos de datos.\n", "\n", "Como hemos hecho arriba con TfidfVectorizer, vamos a entrenar nuestro modelo LDA. Solo debemos tener en cuenta que LDA no trabaja sobre los textos en bruto, sino que debe recibir una representaci\u00f3n vectorial de los mismos. Aprovechando que ya la hemos calculado arriba, hacemos:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lda.fit(vects)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez entrenado el modelo podemos inspeccionarlo de varias formas. Probablemente el dato m\u00e1s interesante es analizar los componentes del modelo, que se refieren a la pertenencia de cada palabra del corpus a cada tema encontrado:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lda.components_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lda.components_.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00bfC\u00f3mo interpretar esta matriz? La matriz tiene tantas filas como temas hayamos pedido a LDA que encuentre, y tantas columnas como palabras en el corpus. Esto significa que si cogemos una columna de esta matriz podremos saber cu\u00e1n relacionada est\u00e1 con cada tema encontrado. Por ejemplo, la siguiente funci\u00f3n toma una palabra, busca con qu\u00e9 \u00edndice ha sido codificado por TF-IDF, y nos devuelve los pesos para cada tema que ha encontrado LDA para ella:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def findwordrelevances(vectorizer, lda, word):\n", "    if word not in vectorizer.get_feature_names():\n", "        print(\"La palabra '%s' no existe en el corpus, o se ha descartado por el vectorizador\" % word)\n", "        return\n", "    idx = vectorizer.get_feature_names().index(word)\n", "    print(\"La palabra '%s' tiene la siguiente relevancia por temas:\" % word)\n", "    print(lda.components_[:,idx])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["findwordrelevances(vectorizer, lda, \"windows\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["findwordrelevances(vectorizer, lda, \"god\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["findwordrelevances(vectorizer, lda, \"jesus\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["findwordrelevances(vectorizer, lda, \"car\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Prueba a buscar otras palabras que creas que puedan ser muy indicativas de uno de los temas que existen realmente en el corpus. \u00bfVes en las relevancia de LDA que est\u00e9 claramente posicionada a favor de uno de los temas?</td></tr>\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Ten en cuenta que LDA es un m\u00e9todo estoc\u00e1stico, lo que significa que los temas encontrados pueden variar en cada ejecuci\u00f3n. Si observas que las relevancias de palabras por temas que aparecen arriba no tienen sentido, prueba a reejecutar la construcci\u00f3n del modelo LDA.</td></tr>\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tambi\u00e9n podemos hacer el an\u00e1lisis en otro sentido: ver qu\u00e9 palabras son las m\u00e1s asociadas con cada tema descubierto por LDA. Para ello vamos a basarnos en las siguientes funciones de utilidad:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_top_words(vectorizer, lda, n_top_words=20):\n", "    \"\"\"Dado un vectorizador y en modelo LDA aplicado sobre \u00e9l, imprime las palabras m\u00e1s relevantes de cada tema\"\"\"\n", "    for topic_idx, topic in enumerate(lda.components_):\n", "        message = \"Topic #%d: \" % topic_idx\n", "        message += \" \".join(top_words_topic(vectorizer, lda, topic_idx, n_top_words))\n", "        print(message)\n", "    print()\n", "    \n", "def top_words_topic(vectorizer, lda, topic_idx, n_top_words=20):\n", "    \"\"\"Devuelve una lista de las palabras m\u00e1s representativas para el i-\u00e9simo tema de un modelo LDA\"\"\"\n", "    feature_names = vectorizer.get_feature_names()\n", "    topic = lda.components_[topic_idx]\n", "    return [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print_top_words(vectorizer, lda)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos ayudarnos tambi\u00e9n de una visualizaci\u00f3n en forma de **nube de palabras** para entender mejor los temas generados. La siguiente funci\u00f3n genera esta visualizaci\u00f3n."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import numpy as np\n", "from wordcloud import WordCloud\n", "\n", "def plot_topics(vectorizer, lda):\n", "    \"\"\"Genera una representaci\u00f3n de nubes de palabras para los temas encontrados por LDA\"\"\"\n", "    feature_names = vectorizer.get_feature_names()\n", "    ntopics = lda.components_.shape[0]\n", "    nrows = int(np.ceil(np.sqrt(ntopics)))\n", "    ncols = int(np.ceil(ntopics / float(nrows)))\n", "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(20,20))\n", "    plainaxes = axs.ravel()\n", "    for topic_idx, topic in enumerate(lda.components_):\n", "        currentax = plainaxes[topic_idx]\n", "        topidx = topic.argsort()\n", "        plt.sca(currentax)\n", "        wcloud = WordCloud(width=400, height=400, background_color='white')\n", "        wcloud.generate_from_frequencies({feature_names[idx]: topic[idx] for idx in topidx})\n", "        plt.imshow(wcloud, interpolation='bilinear')\n", "        sns.despine()\n", "        currentax.set_title(\"Topic %d\" % topic_idx, fontsize=20)\n", "        currentax.axis('off')\n", "    plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9, wspace=0, hspace=0.1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_topics(vectorizer, lda)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finalmente, podemos aplicar el modelo LDA entrenado para obtener la probabilidad de pertenencia a cada tema de un documento vectorizado cualquiera, aplicando la funci\u00f3n transform. Por ejemplo, vamos a tomar el siguiente documento de entrenamiento:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["docindex = 2\n", "print(\"Documento original:\\n\")\n", "print(newsgroups_train.data[docindex])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora le aplicamos la vectorizaci\u00f3n y el modelo LDA, y as\u00ed obtenemos las siguientes pertenencias a cada tema:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectsample = vectorizer.transform([newsgroups_train.data[docindex]])\n", "topics = lda.transform(vectsample)\n", "print(\"\\nProbabilidad de cada tema:\\n\")\n", "print(topics)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00bfTiene sentido esta correspondencia temas? Podemos comprobarlo viendo qu\u00e9 palabras son las m\u00e1s representativas del tema que mayor probabilidad haya obtenido:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nTema m\u00e1s probable: %d\\n\" % np.argmax(topics))\n", "print(\"Palabras m\u00e1s relevantes del tema:\\n\")\n", "print(top_words_topic(vectorizer, lda, np.argmax(topics)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Este proceso puede realizarse con cualquier texto, no solo con los textos que se han usado durante el entrenamiento. Por ejemplo:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sampletext = \"\"\"\n", "We know that all mankind are fallen, we all bear the stain of Adams sin.\n", "But Jesus came to redeem a people for Himself with His blood. Ephesians 1:7\n", "\n", "Believers in Jesus, those who have accepted His Salvation, are now people from every tribe, race, nation and language. Revelation 5:9-10 But God originally chose a people group to be the ones who would be His Witnesses and to display His Light to the world. Those people failed in their task and were ejected for the holy Land in two dispersions.\n", "Those of the second diaspora; the Jewish people have come back to a part of the holy Land, but still in unbelief and apostasy.\n", "\n", "The Bible tells us in many prophesies; that all of Israel, who are by now an uncountable multitude, will return to the holy Land and will fulfil at last, God's plan for them.\n", "The New Testament tells about a symbolic Olive Tree, one that has had all its branches removed. That Tree is Jesus and all who believe in Him, will be grafted into that Tree.\n", "So whether we Christians are actual descendants of Jacob or not, the people who will fulfil God's Plan for a righteous people in His Land; will all be Christians. \n", "\"\"\"\n", "\n", "vectsample = vectorizer.transform([sampletext])\n", "topics = lda.transform(vectsample)\n", "print(\"\\nProbabilidad de cada tema:\\n\")\n", "print(topics)\n", "print(\"\\nTema m\u00e1s probable: %d\\n\" % np.argmax(topics))\n", "print(\"Palabras m\u00e1s relevantes del tema:\\n\")\n", "print(top_words_topic(vectorizer, lda, np.argmax(topics)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\u00bfTiene sentido el tema que se ha asignado al texto?\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## LDA para problemas supervisados"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Latent Dirichlet Analysis tambi\u00e9n puede emplearse para generar variables explicativas de utilidad (los topics) que puedan usarse para reforzar un sistema de clasificaci\u00f3n supervisada. Vamos a ver a continuaci\u00f3n c\u00f3mo hacer esto.\n", "\n", "En primer lugar vamos a construir un sistema de clasificaci\u00f3n b\u00e1sico basado en TF-IDF y una SVM lineal, siguiendo el estilo de ejercicios anteriores:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.svm import LinearSVC\n", "\n", "model = Pipeline([\n", "    ('vectorizer', TfidfVectorizer()),\n", "    ('classifier', LinearSVC())\n", "    ]\n", ")\n", "\n", "model.fit(newsgroups_train.data, newsgroups_train.target)\n", "acc = model.score(newsgroups_test.data, newsgroups_test.target)\n", "print(\"Accuracy on test data\", acc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora vamos a mejorar este Pipeline de clasificaci\u00f3n a\u00f1adiendo variables de LDA. Lo que haremos ser\u00e1 exponer al clasificador (LinearSVC) dos grupos de variables explicativas o _features_:\n", "\n", "* La vectorizaci\u00f3n generada por TF-IDF\n", "* Las probabilidades de pertentencia a cada tema detectador por LDA. N\u00f3tese que para calcular LDA necesitamos previamente haber hecho la vectorizaci\u00f3n TF-IDF.\n", "\n", "En situaciones como esta en la que queremos proporcionar dos o m\u00e1s conjuntos de variables explicativas al clasificador lo que hacemos es definir un Pipeline que calcule cada conjunto de variables por separado. Empezaremos por el Pipeline de TF-IDF:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline_tfidf = Pipeline([\n", "    ('vectorizer', TfidfVectorizer())\n", "])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora definimos otro Pipeline que incluya LDA, para lo cual es pre-requisito haber realizado tambi\u00e9n TF-IDF. Por tanto el Pipeline se compone de estos dos pasos:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline_lda = Pipeline([\n", "    ('vectorizer', TfidfVectorizer()), \n", "    ('lda', LatentDirichletAllocation(n_components=20))\n", "])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez tenemos los Pipelines listos podemos combinarlos usando **FeatureUnion**. Un objeto FeatureUnion recibe una lista de parejas, cada parejas siendo el nombre de ese grupo de features y el Pipeline que lo construye. Un FeatureUnion puede a su vez meterse dentro de un Pipeline de modelado, al que luego puede seguir un clasificador. Por tanto para terminar de definir nuestro modelo escribimos lo siguiente:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.pipeline import FeatureUnion\n", "\n", "model = Pipeline([\n", "    ('merger', FeatureUnion([\n", "        ('tfidf_pipeline', pipeline_tfidf),\n", "        ('topics_pipeline', pipeline_lda),\n", "    ])),\n", "    ('classifier', LinearSVC())   \n", "])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora entrenamos este modelo y medimos el acierto:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(newsgroups_train.data, newsgroups_train.target)\n", "acc = model.score(newsgroups_test.data, newsgroups_test.target)\n", "print(\"Accuracy on test data\", acc)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\u00bfHa mejorado el nivel de acierto tras incluir las variables explicativas basadas en LDA?\n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Otros modelos de detecci\u00f3n de topics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Como alternativa a LDA existen otros modelos que tambi\u00e9n toman como entrada una representaci\u00f3n vectorial de un corpus y tratan de inferir los temas subyacentes a ese corpus. En scikit-learn disponemos de los siguientes:\n", "\n", "* Latent Semantic Analysis (LSA): implementado en la clase [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD).\n", "* Non-negative Matrix Factorization (NMF): implementado en la clase [NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Repite el an\u00e1lisis de descomposici\u00f3n de temas anterior con LSA, construyendo un modelo LSA y generando la gr\u00e1fica de nube de palabras. \u00bfObservas diferencias con la descomposici\u00f3n en temas obtenida por LDA?\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Repite el an\u00e1lisis de nuevo con NMF. \u00bfQu\u00e9 diferencias observas ahora?\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Ahora repite el modelo de clasificaci\u00f3n supervisada con LDA que utilizamos arriba, pero empleando un modelo LSA en su lugar. \u00bfObtienes mejor precisi\u00f3n en test?\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Repite de nuevo con NMF, \u00bfqu\u00e9 resultado en test obtienes ahora?\n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 1}