{"cells": [{"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["# Pr\u00e1ctica: clasificaci\u00f3n autom\u00e1tica de spam"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["<img src=\"img/Spam_can.png\" style=\"width:400px;height:400px;\">"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["En esta pr\u00e1ctica vamos a construir un clasificador autom\u00e1tico de spam, que dado un texto extra\u00eddo de un mensaje SMS nos pueda decir si se trata de un correo leg\u00edtimo o de un mensaje no deseado o fraudulento. Para ello vamos a utilizar m\u00e9todos sencillos de tratamiento de textos, que sin embargo resultan ser muy efectivos para este problema."]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["## Instrucciones"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["A lo largo de este cuaderno encontrar\u00e1s celdas vac\u00edas que tendr\u00e1s que rellenar con tu propio c\u00f3digo. Sigue las instrucciones del cuaderno y presta especial atenci\u00f3n a los siguientes iconos:\n", "\n", "<table>\n", "<tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Deber\u00e1s responder a la pregunta indicada con el c\u00f3digo o contestaci\u00f3n que escribas en la celda inferior.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Esto es una pista u observaci\u00f3n que te puede ayudar a resolver la pr\u00e1ctica.</td></tr>\n", " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">Este es un ejercicio avanzado y voluntario que puedes realizar si quieres profundar m\u00e1s sobre el tema. Te animamos a intentarlo para aprender m\u00e1s \u00a1\u00c1nimo!</td></tr>\n", "</table>\n", "\n", "Para evitar problemas de compatibilidad y de paquetes no instalados, se recomienda ejecutar este notebook bajo uno de los [entornos recomendados de Text Mining](https://github.com/albarji/teaching-environments/tree/master/textmining).\n", "\n", "Adicionalmente si necesitas consultar la ayuda de cualquier funci\u00f3n python puedes colocar el cursor de escritura sobre el nombre de la misma y pulsar May\u00fasculas+Shift para que aparezca un recuadro con sus detalles. Ten en cuenta que esto \u00fanicamente funciona en las celdas de c\u00f3digo.\n", "\n", "\u00a1Adelante!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preliminares"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En primer lugar vamos a fijar la semilla aleatoria para que los resultados sean reproducibles entre diferentes ejecuciones del notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "np.random.seed(12345)"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["## Carga y preparaci\u00f3n de datos"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["Para construir nuestro clasificador autom\u00e1tico de spam vamos a utilizar los datos que puedes encontrar en el fichero *SMSSpamCollection* de la carpeta *data*. En esa misma carpeta encontrar\u00e1s un fichero *readme* con informaci\u00f3n sobre el origen de este conjunto de datos. Vamos a tener que cargar estos ficheros en Python, para lo que antes tendremos que entender c\u00f3mo se estructura este fichero."]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Abre el fichero <i>SMSSpamCollection</i> con cualquier programa de edici\u00f3n de texto, y trata de descubrir:\n", "     <ul>\n", "      <li>\u00bfQu\u00e9 columnas de informaci\u00f3n tiene este fichero?</li>\n", "      <li>\u00bfCu\u00e1l es el caracter separador de columnas?</li>\n", "      <li>\u00bfC\u00f3mo est\u00e1n etiquetadas las clases de mensajes de spam y de mensajes leg\u00edtimos?</li>\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["La forma m\u00e1s efectiva de cargar estos datos es usando la librer\u00eda **pandas**, que no solo da funciones de lectura de ficheros sino tambi\u00e9n de manipulaci\u00f3n de estos datos en memoria."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["La funci\u00f3n m\u00e1s adecuada para realizar la carga de este tipo de fichero es <a href=http://pandas.pydata.org/pandas-docs/version/0.16.2/generated/pandas.read_csv.html>**read_csv**</a>."]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "locked": false, "solution": false}}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Usando la funci\u00f3n <b>read_csv</b>, carga en memoria los datos en una variable con nombre <b>data</b>.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": true, "grade_id": "q1", "locked": false, "points": 1, "solution": true}}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos ahora a comprobar si se ha realizado la carga de los datos correctamente. La funci\u00f3n **read_csv** devuelve un objeto de tipo DataFrame, que permite analizar los datos con facilidad. El siguiente c\u00f3digo deber\u00eda mostrar correctamente tanto los textos como las etiquetas de los 10 primeros mensajes:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Comprueba que al ejecutar la celda anterior se muestran correctamente los datos.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A continuaci\u00f3n vamos a separar estos datos en dos subconjuntos: un conjunto **train** para realizar el entrenamiento de nuestro modelo de clasificaci\u00f3n de spam, y otro conjunto **test** sobre el que probar nuestro modelo para medir as\u00ed el nivel de acierto de nuestra soluci\u00f3n. Para esto vamos a tener que generar dos nuevos DataFrame, **train** y **test** que contengan el 75% y el 25% de los datos, respectivamente. Esto podemos hacerlo f\u00e1cilmente usando la funci\u00f3n apropiada de scikit-learn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "train, test = train_test_split(data, test_size=0.25)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Modelo sencillo basado en caracteres"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Convirtiendo el texto a vectores"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para empezar vamos a construir un modelo que simplemente tenga en cuenta el tipo de caracteres que aparecen en el texto para tratar de determinar si se trata de un mensaje de spam o leg\u00edtimo. Para ello vamos a utilizar la estrategia de CountVectorizer que seguimos en la pr\u00e1ctica anterior."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Crea un objeto de tipo <b>CountVectorizer</b> que analize unigramas de caracteres, haciendo la cuenta de forma binaria. Despu\u00e9s utiliza el vectorizador que has creado para convertir todos los textos del conjunto de entrenamiento <b>train</b>, guardando el resultado en la variable <b>X</b>, que ser\u00e1 la matriz que usaremos para entrenar el clasificador autom\u00e1tico.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Para asegurarte de que has realizado la transformaci\u00f3n correctamente puedes mirar cu\u00e1l es el vocabulario que ha contruido el vectorizador, cu\u00e1l es el contenido del primer texto de <b>train</b>, y ver si cuadra con la representaci\u00f3n vectorial generada en la primera fila de <b>X</b>.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Entrenando el clasificador autom\u00e1tico"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora que tenemos los datos en formato vectorial vamos a construir un modelo con ellos. Como modelo vamos a utilizar una **SVM lineal**, que es un modelo muy frecuentemente utilizado junto con representaciones tipo bag-of-words debido a sus r\u00e1pidos tiempos de entrenamiento y su robustez al enfrentarse con un n\u00famero muy elevado de variables explicativas. Este modelo est\u00e1 tambi\u00e9n disponible en el paquete scikit-learn:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import LinearSVC"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Todos los modelos de scikit-learn funcionan de la misma manera, operando a trav\u00e9s de los siguientes m\u00e9todos:\n", "* **fit**: recibe una matriz X de datos de entrenamiento, y una matriz o vector Y con las etiquetas que deseamos estimar. X debe tener el mismo n\u00famero de filas que Y.\n", "* **predict**: recibe una matrix X de datos de test, y genera una matriz o vector con las etiquetas m\u00e1s probables para cada dato de test. Para invocar este m\u00e9todo antes debe haberse realizado el fit.\n", "* **score**: recibe una matrix X de datos de test, y una matriz o vector Y con las etiquetas que deber\u00eda estimar el modelo. Como resultado devuelve un score o medida de la precisi\u00f3n del modelo, que se calcula comparando las predicciones de modelo contra las etiquetas esperadas que se han proporcionado. Para invocar este m\u00e9todo antes debe haberse realizado el fit."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Entrena un modelo LinearSVC con los datos de entrenamiento <b>X</b> que has preparado. Para ello necesitar\u00e1s crear un objeto del tipo LinearSVC y llamar a su m\u00e9todo train con X y las etiquetas de tu DataFrame <i>train</i>.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para comprobar que el modelo se ha entrenado correctamente, podemos medir el score que tiene sobre los propios datos de entrenamiento. Esta no es una forma adecuada de conseguir una medida realista del error, pero nos sirve para saber que no tenemos fallos en el proceso de entrenamiento."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Calcula el score del modelo con los propios datos de entrenamiento. \u00bfObtienes un nivel de score (precisi\u00f3n del clasificador) razonable?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Evaluando el clasificador autom\u00e1tico"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos ahora a medir c\u00f3mo de bien funciona el clasificador sobre el conjunto de test.\n", "\n", "Para ello vamos a tener que transformar los textos del conjunto de test a vectores siguiendo **exactamente** el mismo proceso que para el entrenamiento. Para conseguir esto tendremos que usar el vocabulario de palabras que se calcul\u00f3 cuando pasamos por el vectorizador los datos de entrenamiento. Esto podemos hacerlo usando la funci\u00f3n **transform** de nuestro vectorizador, que realiza la transformaci\u00f3n usando el vocabulario obtenido en la \u00faltima llamada a **fit_transform**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Utiliza el vectorizador que creaste durante el entrenamiento para convertir todos los textos del conjunto de test <b>test</b>, guardando el resultado en la variable <b>Xtest</b>.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Es importante <b>no reentrenar</b> el vector usando fit_transform para los datos de test. Si lo hacemos estaremos construyendo un vectorizador diferente, que ser\u00e1 incompatible con el modelo que hemos preparado sobre los datos de entrenamiento.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora que tenemos los datos de test en formato vectorial vamos a medir el acierto de nuestro modelo."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Utiliza la funci\u00f3n <b>score</b> del modelo que has creado para medir el acierto sobre los datos de test.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Unificando el proceso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Existe una forma m\u00e1s eficaz de realizar todo el proceso de transformar datos de entrenamiento, construir el modelo, transformar los datos de test y medir la precisi\u00f3n de nuestro modelo sobre ellos. Esa forma es usar un **Pipeline** de scikit-learn:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.pipeline import Pipeline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Un Pipeline nos permite encadenar varios procesos de modelado, de forma que se ejecuten de forma coordinada. Por ejemplo, para encadenar un vectorizador con una SVM no tenemos m\u00e1s que crear el Pipeline de la siguiente manera:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipelineejemplo = Pipeline([\n", "    ('vectorizer', CountVectorizer(analyzer = \"word\", ngram_range = (1,1))),\n", "    ('classifier', LinearSVC())\n", "    ]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El Pipeline se construye suministrando una lista de tuplas, cada tupla conteniendo un elemento procesador y un nombre que decidamos asignarle. Una vez constru\u00eddo podemos ejecutar las tareas de entrenamiento, que incluyen la transformaci\u00f3n de los textos a vectores, ejecutando la funci\u00f3n **fit** del pipeline, para despu\u00e9s hacer predicciones o medir la precisi\u00f3n del modelo sobre datos de test con las funciones **predict** y **score**. En definitiva, un Pipeline se emplea pr\u00e1cticamente de la misma manera que un modelo simple de scikit-learn."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Construye un <b>Pipeline</b> que incluya un vectorizador de unigramas caracteres como el que has usado antes, y una SVM lineal como modelo de clasificaci\u00f3n. A continuaci\u00f3n entrena el pipeline usando los datos de entrenamiento y calcula el score para los datos de test. Ten en cuenta que como el Pipeline ya incluye el paso de transformaci\u00f3n de textos a vectores, los datos que debes suministrar para el entrenamiento y el scoring no son las matrices X y Xtest, sino la lista de textos originales.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Si lo has hecho todo correctamente deber\u00edas haber obtenido el mismo score que en el apartado anterior.\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00bfCu\u00e1l es la utilidad de agrupar todo en un Pipeline como hemos hecho? Principalmente la facilidad de uso que nos da para poder probar varias opciones de procesado y modelado r\u00e1pidamente. En los siguientes apartados vamos a explotar esto."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Modelos de n-gramas m\u00e1s avanzados"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora que hemos constru\u00eddo un modelo sencillo y tenemos una estimaci\u00f3n de lo bien que funciona vamos a probar estrategias m\u00e1s avanzadas para comprobar si podemos mejorar nuestro nivel de precisi\u00f3n a la hora de detectar spam. Para ello vamos a experimentar cambiando las opciones de vectorizaci\u00f3n de nuestro pipeline, buscando qu\u00e9 estrategias funcionan mejor para el problema.\n", "\n", "Lo primero que vamos a hacer es cambiar el modelo de uni-gramas por uno de bi-gramas."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Construye un nuevo <b>Pipeline</b> similar al del apartado anterior pero que en lugar de utilizar solo unigramas incluya tanto <b>unigramas como bigramas</b>. \u00bfQu\u00e9 score obtienes sobre los datos de test? \u00bfEs mejor que el alcanzado por el modelo que solo emplea unigramas?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Construye ahora otro <b>Pipeline</b> que en lugar de construir n-gramas de caracteres lo haga sobre palabras \u00bfQu\u00e9 score obtienes sobre los datos de test? \u00bfEs mejor que el anterior?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "      Ahora intenta construir el mejor <b>Pipeline</b> de procesado posible. Para ello juega con todas las opciones que existen en CountVectorizer. \u00bfCu\u00e1l es el mejor nivel de score que puedes obtener?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Automatizando la selecci\u00f3n de par\u00e1metros"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una de las ventajas de scikit-learn es que podemos implementar f\u00e1cilmente un proceso que autom\u00e1ticamente busque qu\u00e9 parametros son los mejores para nuestro modelo. Esto incluye tanto las opciones que dirigen nuestro vectorizador como los par\u00e1metros del modelo de clasificaci\u00f3n que estamos utilizando. Una de las formas de hacer esto es utilizando un proceso de validaci\u00f3n cruzada, como:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El objeto **GridSearchCV** realiza autom\u00e1ticamente un proceso de validaci\u00f3n cruzada de k-hojas sobre el modelo o pipeline que proporcionemos, probando toda las posibles combinaciones de par\u00e1metros y estimando su precisi\u00f3n. Una vez que la combinaci\u00f3n de modelos de par\u00e1metros con mayor precisi\u00f3n se ha encontrado, el modelo o pipeline se entrena con esos par\u00e1metros usando el dataset completo.\n", "\n", "Cuando trabajamos con un pipeline podemos indicar los par\u00e1metros de los componentes del pipeline a optimizar como el nombre del componente seguido por dos guiones bajos y el nombre del par\u00e1metro. Por ejemplo, para hacer un GridSearchCV que optimice el par\u00e1metro C de la SVM lineal y el par\u00e1metro binary del vectorizador tendr\u00edamos que escribir:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Declaraci\u00f3n del Pipeline\n", "pipelineejemplo = Pipeline([\n", "    ('vectorizer', CountVectorizer(analyzer = \"word\", ngram_range = (1,1))),\n", "    ('classifier', LinearSVC())\n", "    ]\n", ")\n", "\n", "# Declaraci\u00f3n de los par\u00e1metros a optimizar autom\u00e1ticamente, y los valores que se probar\u00e1n para cada uno\n", "paramsejemplo = {\n", "    'classifier__C': [0.1, 1, 10],\n", "    'vectorizer__binary' : [False, True],\n", "}\n", "\n", "# Declaraci\u00f3n de la estrategia de validaci\u00f3n cruzada\n", "modelejemplo = GridSearchCV(pipelineejemplo, paramsejemplo)\n", "\n", "# Ejecuci\u00f3n de todo el proceso de entrenamiento, inclu\u00edda la b\u00fasqueda de par\u00e1metros\n", "modelejemplo.fit(train[\"text\"].values, train[\"class\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Y con esto hemos obtenido un modelo que autom\u00e1ticamente ha seleccionado los mejores valores para los par\u00e1metros que hemos indicado. Podemos averiguar qu\u00e9 parametros son estos mediante inspecci\u00f3n del objeto de modelo que hemos entrenado:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["modelejemplo.best_params_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Imitando el ejemplo anterior construye un pipeline para el que mediante validaci\u00f3n cruzada se optimice el par\u00e1metro C de la SVM, y los par\u00e1metros binary y analyzer del vectorizador. Para ello consulta m\u00e1s arriba cu\u00e1les son los valores posibles para el par\u00e1metro analyzer. Ten en cuenta que al declarar el vectorizador o el clasificador no es necesario asignar los par\u00e1metros que luego vayan a optimizarse en la validaci\u00f3n cruzada. Tras el entrenamiento calcula el score sobre el conjunto de test. \u00bfHas conseguido superar tu mejor resultado?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    \u00bfEl proceso de entrenamiento tarda mucho? Al crear el objeto GridSearchCV puedes pasarle un par\u00e1metro <b>n_jobs</b> en el que indicarle el n\u00famero de procesos que usar para el c\u00e1lculo. Puedes incrementarlo para acelerar el c\u00e1lculo, a cambio de usar m\u00e1s procesadores de tu m\u00e1quina. \u00a1Procura no exceder tu n\u00famero de procesadores!\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Otras formas de vectorizaci\u00f3n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Es posible utilizar alternativas al m\u00e9todo CountVectorizer que hemos estado empleando hasta ahora. Mientras que CountVectorizer esencialmente implementa una estrategia de \"bag-of-words\" para generar un vector que represente el texto, es posible tambi\u00e9n utilizar estrategias tipo \"tf-idf\" o basadas en el \"hashing trick\"."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### tf-idf"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Term Frequency - Inverse Document Frequency (tf-idf) es una t\u00e9cnica similar a bag-of-words, pero en la que se **pesan** cada una de las palabras o tokens seg\u00fan la relevancia que parezcan tener en el texto siendo analizado. Esta relevancia se calcula seg\u00fan el n\u00famero de veces que la palabra aparece en el documento (Term Frequency) dividido por el n\u00famero de documentos del corpus en los que aparece ese mismo t\u00e9rmino (Inverse Document Frequency). Esto nos permite reducir la importancia que tendr\u00e1n en nuestro modelo las palabras generales del idioma que aparecen en casi todos los documentos (stop-words), centr\u00e1ndonos en palabras m\u00e1s distintivas de cada texto."]}, {"cell_type": "markdown", "metadata": {}, "source": ["En scikit-learn el vectorizador de textos mediante tf-idf es la clase <a href=http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html>**TfidfVectorizer**</a>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos emplearla de forma similar a CountVectorizer, como se muestra en este ejemplo"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizadorejemplo = TfidfVectorizer()\n", "ejemplos = [\n", "    \"The cat sat on the mat\",\n", "    \"The dog barked at the cat\",\n", "    \"Dog days\"\n", "]\n", "transformados = vectorizadorejemplo.fit_transform(ejemplos)\n", "transformados.toarray()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En la vectorizaci\u00f3n resultado se observa c\u00f3mo cada palabra cuenta con pesos diferentes.\n", "\n", "Podemos adem\u00e1s inspeccionar el vectorizador para ver qu\u00e9 vocabulario se ha constru\u00eddo:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizadorejemplo.vocabulary_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Igualmente es posible ver qu\u00e9 valores de Inverse Document Frequency (idf) se han calculado para cada palabra de este vocabulario. El siguiente c\u00f3digo recupera del vectorizador los nombres de cada una de las caracter\u00edsticas generadas (get_feature_names) y sus pesos idf:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list(zip(vectorizadorejemplo.get_feature_names(), vectorizadorejemplo.idf_))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Como podemos ver, palabras como \"days\" o \"mat\" tienen mayor puntuaci\u00f3n al aparcer en pocos documentos del corpus."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para entrenar un modelo usando este vectorizador podemos usar la misma estrategia de Pipeline que ya hemos visto:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline = Pipeline([\n", "    ('vectorizer', TfidfVectorizer(ngram_range=(1,1))),\n", "    ('classifier', LinearSVC())\n", "    ]\n", ")\n", "pipeline.fit(train[\"text\"].values, train[\"class\"])\n", "pipeline.score(test[\"text\"].values, test[\"class\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Siguiendo el proceso realizado para CountVectorizer, construye un pipeline para el que mediante validaci\u00f3n cruzada se optimice el par\u00e1metro C de la SVM, y los par\u00e1metros binary y ngram_range del TfidfVectorizer. Para el par\u00e1metro ngram_range usa los valores: (1,1), (1,2) y (1,3). \u00bfSon los resultados mejores que con CountVectorizer?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez entrenado el modelo es posible extraer el mejor vectorizador encontrado sac\u00e1ndolo del Pipeline por su nombre:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.best_estimator_.named_steps[\"vectorizer\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Analiza el vectorizador obtenido en la optimizaci\u00f3n anterior y extrae la lista de las 20 palabras con menor peso idf. \u00bfLas palabras con menor peso idf parecen palabras generales del lenguaje?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Hashing trick"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Otra t\u00e9cnica alternativa a las estrategias basadas en diccionarios como CountVectorizer o tf-idf es usar una funci\u00f3n de hash que para cada palabra a token indique un \u00edndice en un vector de caracter\u00edsticas. Esto puede hacerse mediante la clase <a href=http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html>**HashingVectorizer**</a>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import HashingVectorizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vectorizadorejemplo = HashingVectorizer(n_features=5)\n", "ejemplos = [\n", "    \"The cat sat on the mat\",\n", "    \"The dog barked at the cat\",\n", "    \"Dog days\"\n", "]\n", "transformados = vectorizadorejemplo.fit_transform(ejemplos)\n", "transformados.toarray()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Scikit-learn emplea una funci\u00f3n de hash que puede devolver tanto valores negativos como positivos, adem\u00e1s de aplicar una normalizaci\u00f3n del vector resultado, lo que explica que se obtengan n\u00fameros no enteros. Adem\u00e1s en este ejemplo hemos empleando un tama\u00f1o de vector de caracter\u00edsticas muy peque\u00f1o, ya que lo habitual en esta t\u00e9cnica es generar cientos de miles o millones de caracter\u00edsticas."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Una vez m\u00e1s, podemos usar un Pipeline para entrenar un modelo que emplee este vectorizador"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline = Pipeline([\n", "    ('vectorizer', HashingVectorizer()),\n", "    ('classifier', LinearSVC())\n", "    ]\n", ")\n", "pipeline.fit(train[\"text\"].values, train[\"class\"])\n", "pipeline.score(test[\"text\"].values, test[\"class\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Siguiendo el proceso realizado para CountVectorizer, construye un pipeline para el que mediante validaci\u00f3n cruzada se optimice el par\u00e1metro C de la SVM, y los par\u00e1metros binary y ngram_range del HashingVectorizer. Para el par\u00e1metro ngram_range usa los valores: (1,1), (1,2) y (1,3). \u00bfSon los resultados mejores que con CountVectorizer?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Bonus round: no rest for the spammers"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<table>\n", " <tr>\n", "  <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n", "    Explora todos los par\u00e1metros de los que disponen CountVectorizer, TfidfVectorizer y HashingVectorizer, y trata de encontrar el mejor modelo posible. \u00a1Ten cuidado porque el coste de optimizaci\u00f3n crece exponencialmente con el n\u00famero de par\u00e1metros! \u00bfCu\u00e1l es el mejor score que puedes conseguir?\n", "  </td>\n", " </tr> \n", "</table>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["####### INSERT YOUR CODE HERE"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.8"}}, "nbformat": 4, "nbformat_minor": 1}